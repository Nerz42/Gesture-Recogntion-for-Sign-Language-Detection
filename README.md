# Gesture-Recogntion-for-Sign-Language-Detection
## A Gesture Recognition system that can understand and classify sign language gestures, to simplify the lives of the deaf and dumb.
-----
### Packages used:
- OpenCV 4.0.1
- Keras and Tensorflow

*There are only about 250 certified sign language interpreters in India, translating for a deaf population of between 1.8 million and 7 million. (A 2017 study, based on the estimated number of people with disabilities, by the Census board)*

![image](https://user-images.githubusercontent.com/34964937/61511828-9e658800-aa15-11e9-9e37-5d8b2c60c6ad.png)

With the lack of resources for translation and interpretation of sign language, an easy-to-use tool like this can be deployed in web-apps to support the disabled; in learning platform / classrooms, or as a translation device. 

### The Advantages of a Sign Language Recognition system:

![image](https://user-images.githubusercontent.com/34964937/61511981-22b80b00-aa16-11e9-8836-adf6993ca3bb.png)

This project enabled us to work on different Artificial intelligence concepts, such as Computer vision (using OpenCV) and Video processing using CNN concepts. This concept has great scope for scalability and application in various fields such as Mobile app development, Translator devices and remote access teaching and translation. 

### Future Scope:
1.	Can be developed into a system which will Dynamically take input ( Gesture and Gesture names ) so that trained translators can improve the dataset. 
2.	Dynamic inputs will allow users of different countries to add their Country specific sign-language gestures. 
3.	Can be developed into  a Text-to-Voice system, that will understand a deaf personâ€™s gesture, print the name of the gesture on the screen, and speak out the Gesture name, using NLP or Google API. 



